# Project Title
Data Acquisition and Data Wrangling

# Description
The overarching goal of this project is to undertake comprehensive data wrangling on a collection of datasets characterized by inherent ambiguities. Within this context, my primary objective is to identify and address these ambiguities by employing a diverse array of data wrangling techniques. Through meticulous data cleaning, standardization, and organization, the aim is to transform the initial datasets into a refined, coherent, and structured dataset. This meticulously curated dataset will serve as a solid foundation for subsequent analysis, facilitating insightful interpretations and informed decision-making processes.

# Getting Started
## Dependencies
Jupyter Notebook, Python, Pandas, Numpy, Matplotlib and Seaborn

Using Mac OS
## Approach
Doing Data Acquisition and Data Wrangling for all the 3 datasets and also merging the datasets and concatinating the datasets

# Execution Steps:

## Week 1: Task 1 - Data Acquisition and Data Wrangling on dataset 1 and dataset 2

#### Data Inspection:
Thoroughly examine dataset 1 and dataset 2 to understand their structures, features, and potential issues.

#### Data Cleaning and Standardization:
Apply data cleaning techniques such as removing duplicates, correcting errors, and handling missing values using appropriate methods like imputation or deletion.
Standardize data formats, units, and naming conventions across both datasets to ensure consistency.

#### Combining Datasets:
Merge dataset 1 and dataset 2 into a single unified dataset, combine_data, using methods such as concatenation or merging based on common identifiers.

#### Central Tendency Analysis:
Calculate measures of central tendency (mean, median, mode) for key variables in the combined dataset to understand the central values around which the data is distributed.

## Week 2: Task 2 - Data Acquisition and Wrangling on Dataset 3

#### Data Acquisition:
Obtain Dataset 3 and load it into the analysis environment.

#### Concatenating Datasets:
Concatenate combine_data with Dataset 3 to create an expanded dataset for further analysis.

#### Handling Missing Values and Outliers:
Identify and address missing values and outliers in the combined dataset, ensuring data integrity and reliability.

## Week 3: Checking Skewness and Correlation

#### Skewness Analysis:
Calculate the skewness of the data to understand the asymmetry of its distribution.

#### Correlation Analysis:
Assess the correlation between variables to identify relationships and dependencies within the dataset.

#### Conclusion and Further Analysis:
Summarize the findings from the skewness and correlation analysis and determine any further steps required for data refinement or analysis.
